% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
\begin{abstract}

In this thesis we have four individual contributions to the cosmology and astrostatistics literature. Firstly, we propose a method for improving the accuracy of Bayesian evidence computation using the nested sampling algorithm--we call this method ``gradient nested sampling''. This uses a technique which imposes smoothness assumptions on the likelihood function within the core nested sampling meta-algorithm.  Secondly, we introduce a method of efficient subsampling using control variates for MCMC processes in accessible format for physicists and engineers, which has wide applicabilty in modern data-intensive fields of science and machine learning. We use a toy model likelihood to test this efficient subsampling with other forms of subsampling and employ it with nested sampling. This additionally has relevance within the core machine learning tool of stochastic gradient descent. Thirdly, we suggest methods to improve the compatibility of nested sampling with non-deterministic likelihoods, an underexplored topic within the nested sampling literature. Fourthly we propose an astrophysical example of where and how the efficient control variate subsampling method, introduced in this paper, could be utilised. We take the paper Ref~\cite{Mihaylov_2020} as a reference and explain why and how to implement efficient control variate subsampling within that analysis. To summarise: we improve statistical techniques used to test predictive models that use real world data, with potential applications beyond this thesis in stochastic gradient descent, Bayesian Neural Networks, testing trading models, and astrostatistics.
\end{abstract}
